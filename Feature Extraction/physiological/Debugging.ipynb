{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ecea07a-6eb1-439c-9f2d-2cbda5dec6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportAny=false\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import trapezoid\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from numpy.typing import ArrayLike\n",
    "type FeatureDict = dict[str, np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1038c54b-570f-4b14-89ef-28d48b13cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ STAT FEATURES ##############################\n",
    "\n",
    "def ecg_stat(array: ArrayLike) -> pd.DataFrame:\n",
    "    x = np.array(array)\n",
    "    df = pd.DataFrame(data = [x.max(), x.min(), x.mean(), x.std(),\n",
    "                              stats.kurtosis(x), stats.skew(x), np.quantile(x,0.5),\n",
    "                              np.quantile(x, 0.25), np.quantile(x,0.75),\n",
    "                              np.quantile(x, 0.05), np.quantile(x, 0.95)]).T\n",
    "    df.columns = ['max_ecg', 'min_ecg', 'mean_ecg', 'sd_ecg', 'ku_ecg', 'sk_ecg', 'median_ecg',\n",
    "                  'q1_ecg', 'q3_ecg', 'q05_ecg', 'q95_ecg']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55179b07-2128-47ff-b825-82d97e395f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ HRV FEATURES ##############################    \n",
    "\n",
    "def ecg_peaks(array: ArrayLike, sampling_rate: float=1000) -> np.ndarray:\n",
    "    x = np.array(array)\n",
    "    \n",
    "    # distance : minimal horizontal distance (>= 1) in samples between neighbouring peaks. By default = None\n",
    "    # height : required height of peaks. By default = None\n",
    "    \n",
    "    distance = sampling_rate / 3\n",
    "    #height = x.max() / 2\n",
    "    height = np.quantile(x, 0.99)/2 #use 99th quantile instead of max (to ignore outliers)\n",
    "    r_peaks, _ = signal.find_peaks(x, distance= distance, height=height)\n",
    "    \n",
    "    return r_peaks\n",
    "    \n",
    "    \n",
    "\n",
    "def heart_rate(r_peaks: ArrayLike, sampling_rate: float=1000, upsample_rate: int=4) -> tuple[np.ndarray, np.ndarray]:\n",
    "    x = np.array(r_peaks)\n",
    "    rri = np.diff(x)\n",
    "    rri = 1000 * rri / sampling_rate #convert to ms\n",
    "    hr = 1000 * 60 / rri\n",
    "    \n",
    "    hr_time = np.cumsum(rri) / 1000\n",
    "    hr_time -= hr_time[0] \n",
    "    \n",
    "    interpolation_f = interp1d(hr_time, hr, kind='cubic')\n",
    "    \n",
    "    x = np.arange(1, hr_time.max(), 1/upsample_rate)\n",
    "    hr_interpolated = interpolation_f(x)\n",
    "    return hr_interpolated, x\n",
    "    \n",
    "    \n",
    "def ecg_time(array: ArrayLike, sampling_rate: float = 1000) -> pd.DataFrame:\n",
    "    x = np.array(array)\n",
    "    r_peaks = ecg_peaks(x, sampling_rate=sampling_rate)\n",
    "    \n",
    "    # RR intervals are expressed in number of samples and need to be converted into ms. By default, sampling_rate=1000\n",
    "    # HR is given by: 60/RR intervals in seconds. \n",
    "    \n",
    "    rri = np.diff(r_peaks) #RR intervals\n",
    "    rri = 1000 * rri / sampling_rate #Convert to ms\n",
    "    drri = np.diff(rri) #Difference between successive RR intervals\n",
    "    hr = 1000*60 / rri #Heart rate\n",
    "    \n",
    "    meanHR = hr.mean()\n",
    "    minHR = hr.min()\n",
    "    maxHR = hr.max()\n",
    "    sdHR = hr.std()\n",
    "    modeHR =  maxHR - minHR\n",
    "    nNN = rri.shape[0] / (x.shape[0]/sampling_rate/60) #to get the number of NN intervals per minute\n",
    "    meanNN = rri.mean()\n",
    "    SDSD = drri.std()\n",
    "    CVNN = rri.std()\n",
    "    SDNN = CVNN / meanNN\n",
    "    pNN50 = np.sum(np.abs(drri)>50) / nNN * 100\n",
    "    pNN20 = np.sum(np.abs(drri)>20) / nNN * 100\n",
    "    RMSSD = np.sqrt(np.mean(drri**2))\n",
    "    medianNN = np.quantile(rri, 0.5)\n",
    "    q20NN = np.quantile(rri, 0.2)\n",
    "    q80NN = np.quantile(rri, 0.8)\n",
    "    minNN = rri.min()\n",
    "    maxNN = rri.max()\n",
    "    \n",
    "    # HRV triagular index (HTI): The density distribution D of the RR intervals is estimated. The most frequent\n",
    "    # RR interval lenght X is established. Y= D(X) is the maximum of the sample density distribution.\n",
    "    # The HTI is then obtained as : (the number of total NN intervals)/Y\n",
    "\n",
    "    bins = np.arange(meanNN - 3*CVNN , meanNN + 3*CVNN, 10)\n",
    "    d,_ = np.histogram(rri, bins=bins)\n",
    "    y = d.argmax()\n",
    "    triHRV = nNN / y\n",
    "    \n",
    "    df = pd.DataFrame(data = [meanHR, minHR, maxHR, sdHR, modeHR, nNN, meanNN, \n",
    "                              SDSD, CVNN, SDNN, pNN50, pNN20, RMSSD, medianNN,\n",
    "                              q20NN, q80NN, minNN, maxNN, triHRV]).T\n",
    "    \n",
    "    df.columns = ['meanHR', 'minHR', 'maxHR', 'sdHR', 'modeHR', 'nNN','meanNN', 'SDSD', 'CVNN', \n",
    "                  'SDNN', 'pNN50', 'pNN20', 'RMSSD', 'medianNN', 'q20NN','q80NN','minNN', 'maxNN', 'triHRV']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04f69db-870f-43e2-8d71-56fcaaf13d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ FREQ FEATURES ##############################\n",
    "\n",
    "def interpolate_Rpeaks(peaks: ArrayLike, sampling_rate: float=1000, upsample_rate: int=4) -> tuple[np.ndarray, np.ndarray]:\n",
    "    # Input: An array (numpy, dataframe, list) \n",
    "    # -> Output : A numpy array \n",
    "    \n",
    "    # The RR intervals are aranged over time, and the values are summed up to find the time points.\n",
    "    # An interpolation function is defined, to use to sample from with any upsampling resolution. \n",
    "    # By default upsample_rate = 4 : 4 evenly spaced data points per seconds are added. \n",
    "    \n",
    "    rr = np.diff(peaks)\n",
    "    rr = 1000 * rr / sampling_rate # convert to ms\n",
    "    rr_time = np.cumsum(rr) / 1000 # convert to s\n",
    "    rr_time -= rr_time[0] # shift time axis so it starts at 0\n",
    "    \n",
    "    interpolation_f = interp1d(rr_time, rr, kind='cubic')\n",
    "    \n",
    "    x = np.arange(1, rr_time.max(), 1/upsample_rate)\n",
    "    rr_interpolated = interpolation_f(x)\n",
    "    \n",
    "    return rr_interpolated, x\n",
    "    \n",
    "    \n",
    "    \n",
    "def ecg_freq(\n",
    "    array: ArrayLike,\n",
    "    sampling_rate: float=1000,\n",
    "    upsample_rate: int=4,\n",
    "    freqband_limits: tuple[float, float, float, float, float, float]=(.0, .0033,.04,.15,.4, .5)) -> pd.DataFrame:\n",
    "    # FFT needs evenly sampled data, so the RR-interval can't be used directly and need to\n",
    "    # be interpolated. Then the spectral density of the signal is computed using Welch method.\n",
    "    \n",
    "    x = np.array(array)\n",
    "    r_peaks = ecg_peaks(x, sampling_rate=sampling_rate)\n",
    "    rri, _ = interpolate_Rpeaks(r_peaks, upsample_rate=upsample_rate)\n",
    "    freq, power = signal.welch(x=rri, fs=upsample_rate)\n",
    "    print(freq)\n",
    "    print(power)\n",
    "\n",
    "    pd.set_option(\"display.max_columns\", 10)\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    hrv_freq = nk.hrv_frequency(r_peaks, sampling_rate=sampling_rate, normalize=False, interpolation_rate=upsample_rate)\n",
    "    rlf = hrv_freq['HRV_LF'].iloc[0] / (hrv_freq['HRV_LF'].iloc[0] + hrv_freq['HRV_HF'].iloc[0]) * 100\n",
    "    rhf = hrv_freq['HRV_HF'].iloc[0] / (hrv_freq['HRV_LF'].iloc[0] + hrv_freq['HRV_HF'].iloc[0]) * 100\n",
    "    print(\"HRVFreq Total: {0:.4f}, ulf: {1:.2f}, vlf: {2:.2f}, lf: {3:.2f}, hf: {4:.2f}, vhf: {5:.2f}, lfhf: {6:.2f}, rlf: {7:.2f}, rhf: {8:.2f}\".format(\n",
    "        hrv_freq['HRV_TP'].iloc[0], hrv_freq['HRV_ULF'].iloc[0], hrv_freq['HRV_VLF'].iloc[0], hrv_freq['HRV_LF'].iloc[0],\n",
    "        hrv_freq['HRV_HF'].iloc[0], hrv_freq['HRV_VHF'].iloc[0], hrv_freq['HRV_LFHF'].iloc[0], rlf, rhf)\n",
    "    )\n",
    "    \n",
    "    lim_ulf= (freq >= freqband_limits[0]) & (freq < freqband_limits[1])\n",
    "    lim_vlf = (freq >= freqband_limits[1]) & (freq < freqband_limits[2])\n",
    "    lim_lf = (freq >= freqband_limits[2]) & (freq < freqband_limits[3])\n",
    "    lim_hf = (freq >= freqband_limits[3]) & (freq < freqband_limits[4])\n",
    "    lim_vhf = (freq >= freqband_limits[4]) & (freq < freqband_limits[5])\n",
    "    print(f\"ulf: freq {freq[lim_ulf]} power {power[lim_ulf]}\")\n",
    "    print(f\"vlf: freq {freq[lim_vlf]} power {power[lim_vlf]}\")\n",
    "    print(f\"lf: freq {freq[lim_lf]} power {power[lim_lf]}\")\n",
    "    print(f\"hf: freq {freq[lim_hf]} power {power[lim_hf]}\")\n",
    "    print(f\"vhf: freq {freq[lim_vhf]} power {power[lim_vhf]}\")\n",
    "    \n",
    "    # The power (PSD) of each frequency band is obtained by integrating the spectral density \n",
    "    # by trapezoidal rule, using the scipy.integrate.trapz function.\n",
    "    \n",
    "    ulf = trapezoid(power[lim_ulf], freq[lim_ulf])\n",
    "    vlf = trapezoid(power[lim_vlf], freq[lim_vlf])\n",
    "    lf = trapezoid(power[lim_lf], freq[lim_lf])\n",
    "    hf = trapezoid(power[lim_hf], freq[lim_hf])\n",
    "    vhf = trapezoid(power[lim_vhf], freq[lim_vhf])\n",
    "    totalpower = ulf + vlf + lf + hf + vhf\n",
    "    lfhf = lf / hf\n",
    "    rlf = lf / (lf + hf) * 100\n",
    "    rhf = hf / (lf + hf) * 100\n",
    "\n",
    "    print(f\"Manual Total: {totalpower:.4f}, ulf: {ulf:.2f}, vlf: {vlf:.2f}, lf: {lf:.2f}, hf: {hf:.2f}, vhf: {vhf:.2f}, lfhf: {lfhf}, rlf: {rlf:.2f}, rhf: {rhf:.2f}\")\n",
    "\n",
    "    peaklf = freq[lim_lf][np.argmax(power[lim_lf])]\n",
    "    peakhf = freq[lim_hf][np.argmax(power[lim_hf])]\n",
    "    \n",
    "    df = pd.DataFrame(data = [totalpower, lf, hf, ulf, vlf, vhf, lfhf,\n",
    "                             rlf, rhf, peaklf, peakhf]).T\n",
    "    \n",
    "    df.columns = ['totalpower', 'LF', 'HF', 'ULF', 'VLF', 'VHF', 'LF/HF',\n",
    "                 'rLF', 'rHF', 'peakLF', 'peakHF']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0768b710-1293-4b89-bb66-7c744b5b90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ NONLIN FEATURES ##############################  \n",
    "\n",
    "\n",
    "def apEntropy(array: ArrayLike, m: int=2, r: float | None=None) -> float:\n",
    "    # Input: An array (numpy, dataframe, list) \n",
    "    # -> Output : A Float\n",
    "    \n",
    "    # m : a positive integer representing the length of each compared run of data (a window).\n",
    "    # By default m = 2\n",
    "    # r : a positive real number specifying a filtering level. By default r = 0.2 * sd.\n",
    "    \n",
    "    x = np.array(array)\n",
    "    N = len(x)\n",
    "    r = 0.2 * x.std() if r == None else r == r\n",
    "    \n",
    "    # A sequence of vectors z(1),..., z(N-m+1) is formed from a time series of N equally \n",
    "    # spaced raw data values x(1),…,x(N), such that z(i) = x(1),...,x(i+m-1).\n",
    "    \n",
    "    # For each i in {1,..., N-m+1}, C = [number of z(j) such that d(x(i),x(j)) < r]/[N-m+1]\n",
    "    # is computed, with d(z(i),z(j)) = max|x(i)-x(j)|\n",
    "    \n",
    "    # phi_m(r) = (N-m+1)^-1 x sum log(Ci) is computed, and the ap Entropy is given by: \n",
    "    # phi_m(r) - phi_m+1(r)\n",
    "\n",
    "    def _maxdist(zi, zj):\n",
    "        return max([abs(xi - xj) for xi, xj in zip(zi, zj)])\n",
    "    \n",
    "    def _phi(m):\n",
    "        z = [[x[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [len([1 for zj in z if _maxdist(zi, zj) <= r]) / (N - m + 1.0)\n",
    "        for zi in z]\n",
    "        return (N - m + 1.0) ** (-1) * sum(np.log(C))\n",
    "    \n",
    "    apEn = abs(_phi(m + 1) - _phi(m))\n",
    "    return apEn\n",
    "    \n",
    "    \n",
    "def sampEntropy(array: ArrayLike, m: int=2, r: float | None=None) -> float:\n",
    "    # Input: An array (numpy, dataframe, list) \n",
    "    # -> Output : A Float\n",
    "    \n",
    "    # m: embedding dimension\n",
    "    # r: tolerance distance to consider two data points as similar. By default r = 0.2 * sd.\n",
    "    \n",
    "    # SampEn is the negative logarithm of the probability that if two sets of simultaneous \n",
    "    # data points of length m have distance < r then two sets of simultaneous data points of \n",
    "    # length m + 1 also have distance < r. \n",
    "    \n",
    "    x = np.array(array)\n",
    "    N = len(x)\n",
    "    r = 0.2 * x.std() if r == None else r == r\n",
    "    \n",
    "    # All templates vector of length m are defined. Distances d(xmi, xmj) are computed\n",
    "    # and all matches such that d < r are saved. Same for the distances d(xm+1i, xm+1j).\n",
    "    \n",
    "    xmi = np.array([x[i : i + m] for i in range(N - m)])\n",
    "    xmj = np.array([x[i : i + m] for i in range(N - m + 1)])\n",
    "    B = np.sum([np.sum(np.abs(xmii - xmj).max(axis=1) <= r) - 1 for xmii in xmi])\n",
    "    m += 1\n",
    "    xm = np.array([x[i : i + m] for i in range(N - m + 1)])\n",
    "    A = np.sum([np.sum(np.abs(xmi - xm).max(axis=1) <= r) - 1 for xmi in xm])\n",
    "    \n",
    "    return -np.log(A / B)\n",
    "    \n",
    "    \n",
    "def ecg_nonlinear(array: ArrayLike, sampling_rate: float=1000, m: int=2, r: float | None=None) -> pd.DataFrame:\n",
    "    # The Poincaré ellipse plot is diagram in which each RR intervals are plotted as a function \n",
    "    # of the previous RR interval value. SD1 is the standard deviation spread orthogonally \n",
    "    # to the identity line (y=x) and is the ellipse width. SD2 is the standard deviation spread\n",
    "    # along the identity line and specifies the length of the ellipse.\n",
    "    \n",
    "    x = np.array(array)\n",
    "    r_peaks = ecg_peaks(x, sampling_rate=sampling_rate)\n",
    "    rri = np.diff(r_peaks)\n",
    "    rr1 = rri[:-1]\n",
    "    rr2 = rri[1:]\n",
    "    SD1 =  np.std(rr2 - rr1) / np.sqrt(2)\n",
    "    SD2 =  np.std(rr2 + rr1) / np.sqrt(2)\n",
    "    SD1SD2 = SD1/SD2\n",
    "    apEn = apEntropy(r_peaks, m=2)\n",
    "    sampEn = sampEntropy(r_peaks, m=2)\n",
    "    \n",
    "    df = pd.DataFrame(data = [SD1, SD2, SD1SD2, apEn, sampEn]).T\n",
    "    \n",
    "    df.columns = ['SD1', 'SD2', 'SD1SD2', 'apEn', 'sampEn']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89225a7-4844-4d55-81b5-909c0656494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ ECG API ##############################\n",
    "\n",
    "def ecg_stat_features(dictionary: FeatureDict) -> pd.DataFrame:\n",
    "    data = dictionary.copy()\n",
    "    df_stat = ecg_stat( list(data.values())[0] )\n",
    "    names = [list(data.keys())[0]]\n",
    "    \n",
    "    items = iter(data.items())\n",
    "    _ = next(items)\n",
    "    \n",
    "    for k,v in items:\n",
    "        df_stat = pd.concat([df_stat, ecg_stat(v)], axis=0) \n",
    "        names.append(k)\n",
    "    \n",
    "    return df_stat.set_axis(names)\n",
    "\n",
    "def ecg_time_features(dictionary: FeatureDict, sampling_freq: float =500) -> pd.DataFrame:\n",
    "    data = dictionary.copy()\n",
    "    df_time = ecg_time(list(data.values())[0] , sampling_freq)\n",
    "    names = [list(data.keys())[0]]\n",
    "    \n",
    "    items = iter(data.items())\n",
    "    _ = next(items)\n",
    "    \n",
    "    for k,v in items:\n",
    "        df_time = pd.concat([df_time, ecg_time(v, sampling_freq)], axis=0)\n",
    "        names.append(k)\n",
    "        \n",
    "    return df_time.set_axis(names)\n",
    "\n",
    "\n",
    "def ecg_freq_features(dictionary: FeatureDict, sampling_freq: float =500) -> pd.DataFrame:\n",
    "    data = dictionary.copy()\n",
    "    print(f\"analyzing {list(data.keys())[0]}\")\n",
    "    df_freq = ecg_freq(list(data.values())[0], sampling_freq)\n",
    "    names = [list(data.keys())[0]]\n",
    "    items = iter(data.items())\n",
    "    _ = next(items)\n",
    "    \n",
    "    for k,v in items:\n",
    "        print(f\"analyzing {k}, length: {len(v)}\")\n",
    "        df_freq = pd.concat([df_freq, ecg_freq(v, sampling_freq)], axis=0)\n",
    "        names.append(k)\n",
    "        \n",
    "    return df_freq.set_axis(names)\n",
    "\n",
    "def ecg_nonlinear_features(dictionary: FeatureDict, sampling_freq: float =500) -> pd.DataFrame:\n",
    "    data = dictionary.copy()\n",
    "    df_nonlinear = ecg_nonlinear( list(data.values())[0], sampling_freq)\n",
    "    names = [list(data.keys())[0]]\n",
    "    \n",
    "    items = iter(data.items())\n",
    "    _ = next(items)\n",
    "    \n",
    "    for k,v in items:\n",
    "        df_nonlinear = pd.concat([df_nonlinear, ecg_nonlinear(v, sampling_freq)], axis=0)\n",
    "        names.append(k)\n",
    "        \n",
    "    return df_nonlinear.set_axis(names)\n",
    "\n",
    "\n",
    "def get_ecg_features(dictionary: FeatureDict, sampling_freq: float=500) -> pd.DataFrame:\n",
    "    df_stat = ecg_stat_features(dictionary)\n",
    "    df_time = ecg_time_features(dictionary, sampling_freq)\n",
    "    df_freq = ecg_freq_features(dictionary, sampling_freq)\n",
    "    df_nonlinear = ecg_nonlinear_features(dictionary, sampling_freq)\n",
    "    \n",
    "    df = pd.concat([df_time, df_stat, df_freq, df_nonlinear], axis=1)\n",
    "    #df.set_axis(names, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2068383-909b-4928-bb96-8a573e654e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import neurokit2 as nk\n",
    "\n",
    "from eda_features import get_eda_features\n",
    "\n",
    "EXPECTED_NUM_FILES = 21\n",
    "dataset_path = \"../../../experiment-data\"\n",
    "\n",
    "type FeatureDict = dict[str, np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a743ac8-1680-4ab4-9f22-5c209019e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob(f\"{dataset_path}/*.Annotated.csv\")\n",
    "if len(filelist) != EXPECTED_NUM_FILES:\n",
    "    raise ValueError(f\"Expected {EXPECTED_NUM_FILES} files, found: {len(filelist)}\")\n",
    "\n",
    "data_ecg: FeatureDict = dict()\n",
    "data_eda: FeatureDict = dict()\n",
    "\n",
    "filelist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5c9739-1d59-41e2-bdf3-ffece32b8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_label(df: pd.DataFrame) -> list[tuple[str, pd.DataFrame]]:\n",
    "    output: list[tuple[str, pd.DataFrame]] = []\n",
    "    labels = [\"Baseline\", \"AmusementClip\", \"StressClip\", \"EmoReset\", \"FormL\", \"FormM\", \"Debriefing\"]\n",
    "    start_idx = end_idx = 0\n",
    "    for label in labels:\n",
    "        if label == \"FormL\":\n",
    "            if \"FormLRead\" in df[\"Event\"].values:\n",
    "                start_idx = df.index.get_loc(df[df[\"Event\"] == \"FormLRead\"].index[0])\n",
    "                end_idx = df.index.get_loc(df[df[\"Event\"] == \"L15\"].index[-1])\n",
    "            else:\n",
    "                start_idx = df.index.get_loc(df[df[\"Event\"] == \"FormL\"].index[0])\n",
    "                end_idx = df.index.get_loc(df[df[\"Event\"] == \"FormL\"].index[-1])\n",
    "        elif label == \"FormM\":\n",
    "            if \"FormMRead\" in df[\"Event\"].values:\n",
    "                start_idx = df.index.get_loc(df[df[\"Event\"] == \"FormMRead\"].index[0])\n",
    "                end_idx = df.index.get_loc(df[df[\"Event\"] == \"M15\"].index[-1])\n",
    "            else:\n",
    "                start_idx = df.index.get_loc(df[df[\"Event\"] == \"FormM\"].index[0])\n",
    "                end_idx = df.index.get_loc(df[df[\"Event\"] == \"FormM\"].index[-1])\n",
    "        else:\n",
    "            start_idx = df.index.get_loc(df[df[\"Event\"] == label].index[0])\n",
    "            end_idx = df.index.get_loc(df[df[\"Event\"] == label].index[-1])\n",
    "        output.append((label, df[start_idx:end_idx]))\n",
    "    return output\n",
    "\n",
    "for item in filelist:\n",
    "    file: pd.DataFrame = pd.read_csv(\n",
    "        item,\n",
    "        delimiter=\";\",\n",
    "        parse_dates=[\"Datetime\", \"Timestamp\"],\n",
    "        index_col=[\"Datetime\",],\n",
    "        dtype={\n",
    "            \"Timestamp\": float,\n",
    "            \"Event\": str,\n",
    "            \"ExtraEvent\": str,\n",
    "            \"AccelLN_X\": float,\n",
    "            \"AccelLN_Y\": float,\n",
    "            \"AccelLN_Z\": float,\n",
    "            \"Battery\": float,\n",
    "            \"GSR_Range\": int,\n",
    "            \"Skin_Conductance\": float,\n",
    "            \"Skin_Resistance\": float,\n",
    "            \"Gyro_X\": float,\n",
    "            \"Gyro_Y\": float,\n",
    "            \"Gyro_Z\": float,\n",
    "            \"PPG\": float,\n",
    "            \"Pressure\": float,\n",
    "            \"Temperature\": float,\n",
    "            \"AccelLN_X_Uncal\": int,\n",
    "            \"AccelLN_Y_Uncal\": int,\n",
    "            \"AccelLN_Z_Uncal\": int,\n",
    "            \"Skin_Conductance_Uncal\": int,\n",
    "            \"PPG_Uncal\": int,}\n",
    "        )\n",
    "    filename = item.split(\"/\")[-1]\n",
    "    participant_id = filename.split(\"-\")[1]\n",
    "\n",
    "    for label, event_df in split_by_label(file):\n",
    "        sample_name = f\"{participant_id}-{label}\"\n",
    "        file_ecg = np.array(event_df['PPG_Uncal'])\n",
    "        file_eda = np.array(event_df['Skin_Conductance_Uncal'])\n",
    "\n",
    "        data_ecg[sample_name] = (file_ecg - file_ecg.mean())/file_ecg.std()\n",
    "        data_eda[sample_name] = (file_eda - file_eda.mean())/file_eda.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f436ef-6311-4242-9ae5-b08f0eea2df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA: 147 trials and 24 features\n",
      "analyzing 01-Baseline\n",
      "[0.         0.08888889 0.17777778 0.26666667 0.35555556 0.44444444\n",
      " 0.53333333 0.62222222 0.71111111 0.8        0.88888889 0.97777778\n",
      " 1.06666667 1.15555556 1.24444444 1.33333333 1.42222222 1.51111111\n",
      " 1.6        1.68888889 1.77777778 1.86666667 1.95555556]\n",
      "[  9552.25884825 175675.95000592 198696.08233784 169619.18070705\n",
      "  89398.86506345 118371.52157842  26586.20339689 115248.82544164\n",
      " 110034.33854843  90531.31796941 104408.69384876  68280.83122011\n",
      "  73086.63139454  83690.90481564  81547.14216108  57692.56472063\n",
      "  68782.33977607  35664.30224444  47443.12332468  65130.0152752\n",
      "  14794.6622236     854.07581677   3978.08847063]\n",
      "HRVFreq Total: 50567656.3827, ulf: nan, vlf: 22138796.01, lf: 27881761.20, hf: 536343.86, vhf: 10755.31, lfhf: 51.98, rlf: 98.11, rhf: 1.89\n",
      "ulf: freq [0.] power [9552.25884825]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.08888889] power [175675.95000592]\n",
      "hf: freq [0.17777778 0.26666667 0.35555556] power [198696.08233784 169619.18070705  89398.86506345]\n",
      "vhf: freq [0.44444444] power [118371.52157842]\n",
      "Manual Total: 27881.4804, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 27881.48, vhf: 0.00, lfhf: 0.0, rlf: 0.00, rhf: 100.00\n",
      "analyzing 01-AmusementClip, length: 9216\n",
      "[0.         0.12121212 0.24242424 0.36363636 0.48484848 0.60606061\n",
      " 0.72727273 0.84848485 0.96969697 1.09090909 1.21212121 1.33333333\n",
      " 1.45454545 1.57575758 1.6969697  1.81818182 1.93939394]\n",
      "[ 1501.95921009  4996.66731226  6351.15783913   580.24184477\n",
      " 13965.83916777 18516.69765131 11995.11427053  5159.23838401\n",
      "  4786.03021764  7072.73139093 13158.14297673   556.16846847\n",
      "  3797.55170756 13517.84300166 32796.75527722 14387.40570019\n",
      "  2980.75582059]\n",
      "HRVFreq Total: 2258468.0738, ulf: nan, vlf: 191625.63, lf: 1609920.53, hf: 452962.03, vhf: 3959.88, lfhf: 3.55, rlf: 78.04, rhf: 21.96\n",
      "ulf: freq [0.] power [1501.95921009]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.12121212] power [4996.66731226]\n",
      "hf: freq [0.24242424 0.36363636] power [6351.15783913  580.24184477]\n",
      "vhf: freq [0.48484848] power [13965.83916777]\n",
      "Manual Total: 420.0848, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 420.08, vhf: 0.00, lfhf: 0.0, rlf: 0.00, rhf: 100.00\n",
      "analyzing 01-StressClip, length: 9216\n",
      "[0.         0.12121212 0.24242424 0.36363636 0.48484848 0.60606061\n",
      " 0.72727273 0.84848485 0.96969697 1.09090909 1.21212121 1.33333333\n",
      " 1.45454545 1.57575758 1.6969697  1.81818182 1.93939394]\n",
      "[ 723.58310237 4816.21849051 1595.1994459  2016.22445091 1604.43907391\n",
      " 1267.09843753 1622.09455955 1195.24173333 1178.30776997 1440.17424202\n",
      " 1186.92794508 1248.99708027 1713.24533631 1519.68858157 1660.83519715\n",
      " 1996.00513421 1779.24662981]\n",
      "HRVFreq Total: 1957248.7041, ulf: nan, vlf: 369346.45, lf: 1389530.14, hf: 196024.82, vhf: 2347.29, lfhf: 7.09, rlf: 87.64, rhf: 12.36\n",
      "ulf: freq [0.] power [723.58310237]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.12121212] power [4816.21849051]\n",
      "hf: freq [0.24242424 0.36363636] power [1595.1994459  2016.22445091]\n",
      "vhf: freq [0.48484848] power [1604.43907391]\n",
      "Manual Total: 218.8742, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 218.87, vhf: 0.00, lfhf: 0.0, rlf: 0.00, rhf: 100.00\n",
      "analyzing 01-EmoReset, length: 9216\n",
      "[0.         0.12121212 0.24242424 0.36363636 0.48484848 0.60606061\n",
      " 0.72727273 0.84848485 0.96969697 1.09090909 1.21212121 1.33333333\n",
      " 1.45454545 1.57575758 1.6969697  1.81818182 1.93939394]\n",
      "[  4299.81040303 139017.14036619 124145.3264165   55450.14613126\n",
      "  64139.83559061  38945.40305167  62806.81683261  40047.77483653\n",
      "  55972.57974218  53892.60127556  31332.90908989  39337.00004639\n",
      "   7145.40750428  11735.00940155   1743.10592208   4807.28197813\n",
      "   6954.80288129]\n",
      "HRVFreq Total: 39753077.5843, ulf: nan, vlf: 16818074.05, lf: 22404320.60, hf: 519580.93, vhf: 11102.01, lfhf: 43.12, rlf: 97.73, rhf: 2.27\n",
      "ulf: freq [0.] power [4299.81040303]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.12121212] power [139017.14036619]\n",
      "hf: freq [0.24242424 0.36363636] power [124145.3264165   55450.14613126]\n",
      "vhf: freq [0.48484848] power [64139.83559061]\n",
      "Manual Total: 10884.5741, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 10884.57, vhf: 0.00, lfhf: 0.0, rlf: 0.00, rhf: 100.00\n",
      "analyzing 01-FormL, length: 15360\n",
      "[0.         0.07017544 0.14035088 0.21052632 0.28070175 0.35087719\n",
      " 0.42105263 0.49122807 0.56140351 0.63157895 0.70175439 0.77192982\n",
      " 0.84210526 0.9122807  0.98245614 1.05263158 1.12280702 1.19298246\n",
      " 1.26315789 1.33333333 1.40350877 1.47368421 1.54385965 1.61403509\n",
      " 1.68421053 1.75438596 1.8245614  1.89473684 1.96491228]\n",
      "[  81.92717654 1253.09379666 2119.32248757 1831.96705955 2062.43393222\n",
      " 1454.6500055  1170.3331132  2491.4676358  2090.64315935  246.70028877\n",
      "  515.85878398 1189.40918292   77.35218546 2435.64213886 2483.707572\n",
      " 4288.73833653 1640.94777317 1731.37927933 4127.63267945 1451.52145113\n",
      " 3469.76913143 5849.38234219 3525.19549169 1304.50638069  822.30548976\n",
      " 1290.71509134 1261.62056549  504.75784886 1908.37286199]\n",
      "HRVFreq Total: 1256718.7043, ulf: nan, vlf: 161395.86, lf: 884335.56, hf: 208065.56, vhf: 2921.72, lfhf: 4.25, rlf: 80.95, rhf: 19.05\n",
      "ulf: freq [0.] power [81.92717654]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.07017544 0.14035088] power [1253.09379666 2119.32248757]\n",
      "hf: freq [0.21052632 0.28070175 0.35087719] power [1831.96705955 2062.43393222 1454.6500055 ]\n",
      "vhf: freq [0.42105263 0.49122807] power [1170.3331132 2491.4676358]\n",
      "Manual Total: 506.8667, ulf: 0.00, vlf: 0.00, lf: 118.33, hf: 260.05, vhf: 128.48, lfhf: 0.4550257224190541, rlf: 31.27, rhf: 68.73\n",
      "analyzing 01-FormM, length: 18432\n",
      "[0.         0.05714286 0.11428571 0.17142857 0.22857143 0.28571429\n",
      " 0.34285714 0.4        0.45714286 0.51428571 0.57142857 0.62857143\n",
      " 0.68571429 0.74285714 0.8        0.85714286 0.91428571 0.97142857\n",
      " 1.02857143 1.08571429 1.14285714 1.2        1.25714286 1.31428571\n",
      " 1.37142857 1.42857143 1.48571429 1.54285714 1.6        1.65714286\n",
      " 1.71428571 1.77142857 1.82857143 1.88571429 1.94285714 2.        ]\n",
      "[ 1434.46761038  4377.60658     5610.40071963  7579.92072493\n",
      " 24231.9699219  26442.92623614 18936.64155719 11143.06555333\n",
      " 34079.66245714 21538.06907038  6239.20632964 27051.19058124\n",
      " 26843.84180382 24182.65449741 18984.65072089 11892.07455206\n",
      " 17058.91864147 16108.31899224 11763.4403451  20942.40870635\n",
      " 20877.92266945 15795.73810495  3145.2605789   8181.37174685\n",
      " 29271.69510087 27295.20756855 12961.63219796  8604.6036991\n",
      "  5401.57674435 22815.8328772   7008.79368978  4519.01400693\n",
      " 22028.22065059 27320.88329043  3761.96248839  1762.87842724]\n",
      "HRVFreq Total: 7424180.5864, ulf: nan, vlf: 2883111.54, lf: 3920031.83, hf: 612182.94, vhf: 8854.28, lfhf: 6.40, rlf: 86.49, rhf: 13.51\n",
      "ulf: freq [0.] power [1434.46761038]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.05714286 0.11428571] power [4377.60658    5610.40071963]\n",
      "hf: freq [0.17142857 0.22857143 0.28571429 0.34285714 0.4       ] power [ 7579.92072493 24231.9699219  26442.92623614 18936.64155719\n",
      " 11143.06555333]\n",
      "vhf: freq [0.45714286] power [34079.66245714]\n",
      "Manual Total: 4798.1163, ulf: 0.00, vlf: 0.00, lf: 285.37, hf: 4512.74, vhf: 0.00, lfhf: 0.06323682396114005, rlf: 5.95, rhf: 94.05\n",
      "analyzing 01-Debriefing, length: 13306\n",
      "[0.         0.08163265 0.16326531 0.24489796 0.32653061 0.40816327\n",
      " 0.48979592 0.57142857 0.65306122 0.73469388 0.81632653 0.89795918\n",
      " 0.97959184 1.06122449 1.14285714 1.2244898  1.30612245 1.3877551\n",
      " 1.46938776 1.55102041 1.63265306 1.71428571 1.79591837 1.87755102\n",
      " 1.95918367]\n",
      "[  6929.10535331 574256.62929731 934738.57551753 398790.38217059\n",
      " 315962.33216964 207298.32870241  63506.00929444  79161.80415846\n",
      " 235953.50230204 162604.96064402  83363.50990687 239010.05446373\n",
      " 468660.19017664 472213.925399   598116.0449925  784330.50265639\n",
      " 771045.41674359 654267.0764941  328586.34898183  96506.06260576\n",
      "  19706.78260698  64624.27144465  97370.7014479   33934.81975538\n",
      "  22905.03072529]\n",
      "HRVFreq Total: 99744536.1034, ulf: nan, vlf: 24135567.26, lf: 74145563.53, hf: 1428001.58, vhf: 35403.73, lfhf: 51.92, rlf: 98.11, rhf: 1.89\n",
      "ulf: freq [0.] power [6929.10535331]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.08163265] power [574256.62929731]\n",
      "hf: freq [0.16326531 0.24489796 0.32653061] power [934738.57551753 398790.38217059 315962.33216964]\n",
      "vhf: freq [0.40816327 0.48979592] power [207298.32870241  63506.00929444]\n",
      "Manual Total: 94656.5718, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 83603.33, vhf: 11053.24, lfhf: 0.0, rlf: 0.00, rhf: 100.00\n",
      "analyzing 02-Baseline, length: 9574\n",
      "[0.         0.11764706 0.23529412 0.35294118 0.47058824 0.58823529\n",
      " 0.70588235 0.82352941 0.94117647 1.05882353 1.17647059 1.29411765\n",
      " 1.41176471 1.52941176 1.64705882 1.76470588 1.88235294 2.        ]\n",
      "[1.11385958e+06 4.96230165e+06 8.59101721e+06 7.64813462e+06\n",
      " 6.31723840e+06 4.97831110e+06 3.45028561e+06 2.42439985e+06\n",
      " 1.47002534e+06 7.16557992e+05 3.88195996e+05 1.80456388e+05\n",
      " 7.25225815e+04 2.75700041e+04 2.95395283e+04 1.44158525e+04\n",
      " 1.31413047e+03 4.81367732e+01]\n",
      "HRVFreq Total: 348564687.8442, ulf: nan, vlf: 232452220.36, lf: 114814856.87, hf: 1269396.98, vhf: 28213.63, lfhf: 90.45, rlf: 98.91, rhf: 1.09\n",
      "ulf: freq [0.] power [1113859.57885447]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.11764706] power [4962301.65420337]\n",
      "hf: freq [0.23529412 0.35294118] power [8591017.20505632 7648134.6193432 ]\n",
      "vhf: freq [0.47058824] power [6317238.39604621]\n",
      "Manual Total: 955244.2250, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 955244.22, vhf: 0.00, lfhf: 0.0, rlf: 0.00, rhf: 100.00\n",
      "analyzing 02-AmusementClip, length: 8498\n",
      "[0.         0.13333333 0.26666667 0.4        0.53333333 0.66666667\n",
      " 0.8        0.93333333 1.06666667 1.2        1.33333333 1.46666667\n",
      " 1.6        1.73333333 1.86666667 2.        ]\n",
      "[1550.96492809 8324.73984457 2251.24143565 2131.36345004  297.32525688\n",
      "  292.31583697   22.79835615  384.74396078  417.83642662  263.43072001\n",
      " 1001.01817475 1157.86720342  774.70543202 1485.29605206 1495.13086661\n",
      "  362.7812762 ]\n",
      "HRVFreq Total: 5261075.9748, ulf: nan, vlf: 447061.99, lf: 3356042.31, hf: 1441065.64, vhf: 16906.04, lfhf: 2.33, rlf: 69.96, rhf: 30.04\n",
      "ulf: freq [0.] power [1550.96492809]\n",
      "vlf: freq [] power []\n",
      "lf: freq [0.13333333] power [8324.73984457]\n",
      "hf: freq [0.26666667] power [2251.24143565]\n",
      "vhf: freq [0.4] power [2131.36345004]\n",
      "Manual Total: 0.0000, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 0.00, vhf: 0.00, lfhf: nan, rlf: nan, rhf: nan\n",
      "analyzing 02-StressClip, length: 5375\n",
      "[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n",
      "[ 2228.25741931 11358.55644244 12089.66337566  5638.02645748\n",
      "  4533.51230542  8381.22851819 15103.00070607 19530.56779259\n",
      " 10913.05363798]\n",
      "HRVFreq Total: 100100.1758, ulf: nan, vlf: nan, lf: 48270.75, hf: 48571.30, vhf: 3258.13, lfhf: 0.99, rlf: 49.84, rhf: 50.16\n",
      "ulf: freq [0.] power [2228.25741931]\n",
      "vlf: freq [] power []\n",
      "lf: freq [] power []\n",
      "hf: freq [0.25] power [11358.55644244]\n",
      "vhf: freq [] power []\n",
      "Manual Total: 0.0000, ulf: 0.00, vlf: 0.00, lf: 0.00, hf: 0.00, vhf: 0.00, lfhf: nan, rlf: nan, rhf: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m df_eda_features = get_eda_features(eda_clean, \u001b[32m51.2\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEDA: \u001b[39m\u001b[38;5;132;01m{0:2d}\u001b[39;00m\u001b[33m trials and \u001b[39m\u001b[38;5;132;01m{1:2d}\u001b[39;00m\u001b[33m features\u001b[39m\u001b[33m'\u001b[39m.format(df_eda_features.shape[\u001b[32m0\u001b[39m], df_eda_features.shape[\u001b[32m1\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m df_ecg_features = \u001b[43mget_ecg_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecg_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m51.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mECG : \u001b[39m\u001b[38;5;132;01m{0:2d}\u001b[39;00m\u001b[33m trials and \u001b[39m\u001b[38;5;132;01m{1:2d}\u001b[39;00m\u001b[33m features\u001b[39m\u001b[33m'\u001b[39m.format(df_ecg_features.shape[\u001b[32m0\u001b[39m], df_ecg_features.shape[\u001b[32m1\u001b[39m]))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mget_ecg_features\u001b[39m\u001b[34m(dictionary, sampling_freq)\u001b[39m\n\u001b[32m     63\u001b[39m df_stat = ecg_stat_features(dictionary)\n\u001b[32m     64\u001b[39m df_time = ecg_time_features(dictionary, sampling_freq)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m df_freq = \u001b[43mecg_freq_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_freq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m df_nonlinear = ecg_nonlinear_features(dictionary, sampling_freq)\n\u001b[32m     68\u001b[39m df = pd.concat([df_time, df_stat, df_freq, df_nonlinear], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mecg_freq_features\u001b[39m\u001b[34m(dictionary, sampling_freq)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33manalyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     df_freq = pd.concat([df_freq, \u001b[43mecg_freq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_freq\u001b[49m\u001b[43m)\u001b[49m], axis=\u001b[32m0\u001b[39m)\n\u001b[32m     43\u001b[39m     names.append(k)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df_freq.set_axis(names)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mecg_freq\u001b[39m\u001b[34m(array, sampling_rate, upsample_rate, freqband_limits)\u001b[39m\n\u001b[32m     72\u001b[39m rhf = hf / (lf + hf) * \u001b[32m100\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mManual Total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotalpower\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, ulf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mulf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, vlf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvlf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, lf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, hf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, vhf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvhf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, lfhf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlfhf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, rlf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrlf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, rhf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrhf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m peaklf = freq[lim_lf][\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlim_lf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     77\u001b[39m peakhf = freq[lim_hf][np.argmax(power[lim_hf])]\n\u001b[32m     79\u001b[39m df = pd.DataFrame(data = [totalpower, lf, hf, ulf, vlf, vhf, lfhf,\n\u001b[32m     80\u001b[39m                          rlf, rhf, peaklf, peakhf]).T\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/PhDCourse/UXFrustrationRecognition/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:1341\u001b[39m, in \u001b[36margmax\u001b[39m\u001b[34m(a, axis, out, keepdims)\u001b[39m\n\u001b[32m   1252\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1253\u001b[39m \u001b[33;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[32m   1254\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1338\u001b[39m \u001b[33;03m(2, 1, 4)\u001b[39;00m\n\u001b[32m   1339\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1340\u001b[39m kwds = {\u001b[33m'\u001b[39m\u001b[33mkeepdims\u001b[39m\u001b[33m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np._NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/PhDCourse/UXFrustrationRecognition/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mValueError\u001b[39m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "####### CLEAN USING NK\n",
    "ecg_clean = data_ecg.copy()\n",
    "eda_clean = data_eda.copy()\n",
    "\n",
    "for ecg,eda in zip(data_ecg.items(), data_eda.items()):\n",
    "    #ecg_clean[ecg[0]] = nk.ecg_clean(ecg[1], sampling_rate=51.2, method=\"neurokit\")\n",
    "    ecg_clean[ecg[0]] = ecg[1].copy()\n",
    "    eda_clean[eda[0]] = nk.eda_clean(eda[1], sampling_rate=51.2, method='neurokit')\n",
    "\n",
    "\n",
    "    \n",
    "######## EXTRACT FEATURES BY MODALITY    \n",
    "df_eda_features = get_eda_features(eda_clean, 51.2)\n",
    "print('EDA: {0:2d} trials and {1:2d} features'.format(df_eda_features.shape[0], df_eda_features.shape[1]))\n",
    "\n",
    "df_ecg_features = get_ecg_features(ecg_clean, 51.2)\n",
    "print('ECG : {0:2d} trials and {1:2d} features'.format(df_ecg_features.shape[0], df_ecg_features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a98c63-52f2-4e84-8170-716d172ff3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## MERGE\n",
    "df_features = pd.concat([df_ecg_features, df_eda_features], axis=1)\n",
    "\n",
    "\n",
    "####### EXPORT\n",
    "df_eda_features.to_csv(f'{dataset_path}/extracted-features/eda_features.csv', sep=\";\", index=True)\n",
    "df_ecg_features.to_csv(f'{dataset_path}/extracted-features/ecg_features.csv', sep=\";\", index=True)\n",
    "df_features.to_csv(f'{dataset_path}/extracted-features/all_features.csv', sep=\";\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ab607-fad3-4fbf-9642-0b23bb30a6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
